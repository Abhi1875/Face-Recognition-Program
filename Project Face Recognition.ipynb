{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec7d2c32",
   "metadata": {},
   "source": [
    "# Project Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae317fec",
   "metadata": {},
   "source": [
    "1.Collect data of various persons\n",
    "  - Ask multiple people to come in front of the web cam and click 20 pictures of each individual\n",
    "  - Store the part of the image containing the image (haarcascade to detect the face)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22261c86",
   "metadata": {},
   "source": [
    "2.Train a classifier to learn who the person is (classification)\n",
    "  -Load the training Data (.npy arrays)\n",
    "  -Store the data and target values (labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470caa79",
   "metadata": {},
   "source": [
    "3.Predicting the name of the person\n",
    "  -Read the video stream\n",
    "  -Extract the face out of it\n",
    "  -predict the label for that face\n",
    "       -logistic regression (parametric algorithm)\n",
    "       -neural network\n",
    "       -K-NN (non-parametric: look for similarity in nearest neighbours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e33f54d",
   "metadata": {},
   "source": [
    "Object Detection(using haarcascade classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9230ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read an image or video from WebCam using OpenCv\n",
    "#Face detection in video\n",
    "#Click 20 pictures of the person who comes in front of the camera and save them as numpy\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Create a camera object\n",
    "cam=cv2.VideoCapture(0)\n",
    "\n",
    "#Ask the name\n",
    "fileName=input(\"Enter the name of the person:\")\n",
    "dataset_path=r\"C:\\Users\\abhis\\Documents\\data_face\\data\\\\\"\n",
    "offset=20\n",
    "\n",
    "#model\n",
    "model=cv2.CascadeClassifier(r\"C:\\Users\\abhis\\Downloads\\raw.githubusercontent.com_avelino_python-opencv-detect_master_haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "#Create a list to save face data\n",
    "faceData=[]\n",
    "skip=0\n",
    "\n",
    "#Read image from camera object\n",
    "while True:\n",
    "    success,img=cam.read()\n",
    "    if not success:\n",
    "        print(\"Camera reading failed\")\n",
    "    \n",
    "    #Store the gray image, on the UI only the colored images will be shown\n",
    "    grayImg=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces=model.detectMultiScale(img,1.3,5)\n",
    "    #pick the face with largest bounding box\n",
    "    faces=sorted(faces,key=lambda f:f[2]*f[3]) #Here this represents the area w*h\n",
    "    #pick the largest face\n",
    "    if len(faces)>0:  #this condition is imposed so that the program would not crash if there are no elements in the array i.e. if the person face moves sideways no face is detected\n",
    "        f=faces[-1] #since it is sorted so the last image will have the largest bounding box\n",
    "\n",
    "        x,y,w,h=f\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "    \n",
    "        #crop and save the largest face\n",
    "        cropped_face=img[y-offset:y+h+offset,x-offset:x+w+offset]  #slicing operation, y is written first because row is mentioned first and then column\n",
    "        cropped_face=cv2.resize(cropped_face,(100,100))\n",
    "        skip+=1\n",
    "        \n",
    "        if skip%10==0:\n",
    "            faceData.append(cropped_face)\n",
    "            print(\"Saved so far \" + str(len(faceData)))\n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"Image Window\",img)\n",
    "#     cv2.imshow(\"Cropped Face\",cropped_face)\n",
    "    \n",
    "    key=cv2.waitKey(1)  #Pause here for 1ms before you read the next image\n",
    "    if key==ord('q'):\n",
    "        break\n",
    "        \n",
    "#Write the faceData on the Disk so that we reuse it later\n",
    "faceData=np.asarray(faceData)\n",
    "# print(faceData.shape)\n",
    "m=faceData.shape[0]  #number of pictures clicked\n",
    "faceData=faceData.reshape((m,-1))    #13,100,100,3=m,-1   so -1 will automatically get updated to the value 100*100*3\n",
    "print(faceData.shape)\n",
    "#Save on the Disk as np array\n",
    "filepath=dataset_path+fileName+\".npy\"\n",
    "np.save(filepath,faceData)\n",
    "print(\"Data Saved Successfully\"+filepath)\n",
    "\n",
    "#Release camera and destroy window\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32d4b271",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'offset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 78\u001b[0m\n\u001b[0;32m     75\u001b[0m x,y,w,h\u001b[38;5;241m=\u001b[39mf\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m#crop and save the largest face\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m cropped_face\u001b[38;5;241m=\u001b[39mimg[y\u001b[38;5;241m-\u001b[39m\u001b[43moffset\u001b[49m:y\u001b[38;5;241m+\u001b[39mh\u001b[38;5;241m+\u001b[39moffset,x\u001b[38;5;241m-\u001b[39moffset:x\u001b[38;5;241m+\u001b[39mw\u001b[38;5;241m+\u001b[39moffset]  \u001b[38;5;66;03m#slicing operation, y is written first because row is mentioned first and then column\u001b[39;00m\n\u001b[0;32m     79\u001b[0m cropped_face\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mresize(cropped_face,(\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m100\u001b[39m))   \u001b[38;5;66;03m#openCv resize(only 2 coordinates) is different from numpy reshape(3 coordinates i.e. has color channels also) \u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m#cv2.imshow(\"Image Window\",img)\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m#Predict the name using KNN\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'offset' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#Data Preparation\n",
    "dataset_path=r\"C:\\Users\\abhis\\Documents\\data_face\\\\\"\n",
    "faceData=[]\n",
    "labels=[]\n",
    "nameMap={}\n",
    "\n",
    "classId=0\n",
    "\n",
    "for f in os.listdir(dataset_path):\n",
    "#     print(f)\n",
    "    if f.endswith(\".npy\"):\n",
    "        nameMap[classId]=f[34:-4]\n",
    "        #X-value\n",
    "        dataItem=np.load(dataset_path+f)\n",
    "        m=dataItem.shape[0]\n",
    "        faceData.append(dataItem)\n",
    "#         print(dataItem.shape)       \n",
    "        \n",
    "        #Y-values\n",
    "        target=classId*np.ones((m,))\n",
    "        classId+=1\n",
    "        labels.append(target)\n",
    "        \n",
    "# print(faceData)\n",
    "# print(labels)\n",
    "\n",
    "XT=np.concatenate(faceData,axis=0)\n",
    "yT=np.concatenate(labels,axis=0).reshape((-1,1))  #instead of having it as a vector we can have a column vector\n",
    "\n",
    "# print(XT.shape)\n",
    "# print(yT.shape)\n",
    "# print(nameMap)\n",
    "\n",
    "#Algorithm\n",
    "def dist(p,q):\n",
    "    return np.sqrt(np.sum((p-q)**2))\n",
    "\n",
    "def knn(X,y,xt,k=5):\n",
    "    m=X.shape[0]\n",
    "    dlist=[]\n",
    "    \n",
    "    for i in range(m):\n",
    "        d=dist(X[i],xt)\n",
    "        dlist.append((d,y[i]))\n",
    "        \n",
    "    dlist=sorted(dlist)\n",
    "    dlist=np.array(dlist[:k])\n",
    "    labels=dlist[:,-1]\n",
    "    \n",
    "    labels,cnts=np.unique(labels,return_counts=True)\n",
    "    idx=cnts.argmax()\n",
    "    pred=labels[idx]\n",
    "    \n",
    "    return int(pred)\n",
    "\n",
    "#Predictions\n",
    "# Create a camera object\n",
    "cam=cv2.VideoCapture(0)\n",
    "model=cv2.CascadeClassifier(r\"C:\\Users\\abhis\\Downloads\\raw.githubusercontent.com_avelino_python-opencv-detect_master_haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "while True:\n",
    "    success,img=cam.read()\n",
    "    if not success:\n",
    "        print(\"Camera reading failed\")  \n",
    "    \n",
    "    faces=model.detectMultiScale(img,1.3,5)\n",
    "    \n",
    "    #render a box around each face and predict its name\n",
    "    for f in faces:\n",
    "\n",
    "        x,y,w,h=f\n",
    "    \n",
    "        #crop and save the largest face\n",
    "        cropped_face=img[y-offset:y+h+offset,x-offset:x+w+offset]  #slicing operation, y is written first because row is mentioned first and then column\n",
    "        cropped_face=cv2.resize(cropped_face,(100,100))   #openCv resize(only 2 coordinates) is different from numpy reshape(3 coordinates i.e. has color channels also) \n",
    "    \n",
    "        #cv2.imshow(\"Image Window\",img)\n",
    "        #Predict the name using KNN\n",
    "        classPredicted=knn(XT,yT,cropped_face.flatten())\n",
    "        #Name\n",
    "        namePredicted=nameMap[classPredicted]\n",
    "        #Display the name and box\n",
    "        cv2.putText(img,namePredicted,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,1,(0,200,0),2,cv2.LINE_AA)\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        \n",
    "    cv2.imshow(\"Prediction Window\",img)\n",
    "    \n",
    "    key=cv2.waitKey(1)  #Pause here for 1ms before you read the next image\n",
    "    if key==ord('q'):\n",
    "        break\n",
    "        \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6063bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
